#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è XGBoost –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (61 —Ñ–∏—á–∞)
–¶–µ–ª—å: –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å LSTM –º–æ–¥–µ–ª—å—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –æ–±—É—á–µ–Ω–∞ –Ω–∞ 61 –ø—Ä–∏–∑–Ω–∞–∫–µ
"""

import os
import sys
import logging
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–∞–ª–æ–≥ src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏
from data_loader import GoldDataLoader
from features import FeatureGenerator
from models import XGBoostModel
from predict import GoldPredictor

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'logs'))
os.makedirs(log_dir, exist_ok=True)
log_file_path = os.path.join(log_dir, 'retrain_xgboost.log')

# –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è –≤—Å–µ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ logging
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

# –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–æ–≤
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –º–æ–¥–∞ –∑–∞–ø–∏—Å–∏
file_handler = logging.FileHandler(log_file_path, mode='w')
file_handler.setFormatter(formatter)

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä
logging.root.setLevel(logging.INFO)
logging.root.addHandler(file_handler)
logging.root.addHandler(console_handler)

# –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–æ–¥—É–ª—è
logger = logging.getLogger(__name__)
logger.info("–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ XGBoost...")

def retrain_xgboost(period='10y', target_type='binary', horizon=1, use_bybit=True, n_estimators=200, max_depth=5, learning_rate=0.1):
    """
    –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ XGBoost –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –∏–∑ 61 –ø—Ä–∏–∑–Ω–∞–∫–∞.
    
    Args:
        period (str): –ü–µ—Ä–∏–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        target_type (str): –¢–∏–ø —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ('binary', 'regression', 'classification')
        horizon (int): –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ –¥–Ω—è—Ö)
        use_bybit (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Bybit –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        n_estimators (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –º–æ–¥–µ–ª–∏ XGBoost
        max_depth (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤
        learning_rate (float): –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    
    Returns:
        str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    logger.info(f"–ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è XGBoost –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –∏–∑ 61 –ø—Ä–∏–∑–Ω–∞–∫–∞ (–≤–º–µ—Å—Ç–æ 53)")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ {period}")
    loader = GoldDataLoader()
    data = loader.download_data(period=period)
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º os –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤–∏–¥–∏–º–æ—Å—Ç–∏
    import os
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å Bybit –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    if use_bybit:
        logger.info("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Bybit API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö —Ü–µ–Ω")
        try:
            data_path = os.path.join(loader.data_dir, 'GC_F_latest.csv')
            
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if not os.path.exists(data_path):
                loader.save_data(data, 'GC_F_latest.csv')
                
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º update_gold_history_from_bybit –∏–∑ –º–æ–¥—É–ª—è data_updater
            from data_updater import update_gold_history_from_bybit
            
            # API –∫–ª—é—á–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ (–∏–∑ data_updater.py), –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∑–∞–º–µ–Ω–∏—Ç—å
            api_key = 'vcpsoaLUBwfj1jPfCz'
            api_secret = 'xf4WxWufuFleJuAjVWXdxRe6WHugoKPbCqQE'
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Bybit
            update_success = update_gold_history_from_bybit(data_path, api_key, api_secret)
            
            if update_success:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                updated_data = loader.load_data('GC_F_latest.csv')
                if updated_data is not None and not updated_data.empty:
                    logger.info(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã —Å Bybit –¥–æ {updated_data.index[-1]}")
                    data = updated_data
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Bybit: {str(e)}")
            logger.info("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏–º–µ—é—â–∏–º–∏—Å—è –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Yahoo Finance")
    
    if data is None or len(data) < 100:
        logger.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return None
    
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö —Å {data.index[0]} –ø–æ {data.index[-1]}")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_gen = FeatureGenerator(scaling_method='standard')
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
    features_df = feature_gen.prepare_features(data, horizon=horizon, target_type=target_type)
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π...")
    features_df = features_df.ffill().bfill()
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    all_features = list(features_df.drop(['Target'], axis=1).columns)
    logger.info(f"–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(all_features)}")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    test_size = int(len(features_df) * 0.2)  # 20% –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    val_size = int(len(features_df) * 0.1)   # 10% –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    train_data = features_df.iloc[:-test_size-val_size]
    val_data = features_df.iloc[-test_size-val_size:-test_size]
    test_data = features_df.iloc[-test_size:]
    
    logger.info(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {train_data.shape}")
    logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {val_data.shape}")
    logger.info(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {test_data.shape}")
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å XGBoost
    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ XGBoost –º–æ–¥–µ–ª–∏...")
    xgb_model = XGBoostModel(target_type=target_type)
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
    logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã XGBoost: n_estimators={n_estimators}, max_depth={max_depth}, learning_rate={learning_rate}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    xgb_model.params['eta'] = learning_rate
    xgb_model.params['max_depth'] = max_depth
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è XGBoost
    X_train = train_data.drop(['Target'], axis=1)
    y_train = train_data['Target']
    
    X_val = val_data.drop(['Target'], axis=1)
    y_val = val_data['Target']
    
    X_test = test_data.drop(['Target'], axis=1)
    y_test = test_data['Target']
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º —á–∏—Å–ª–æ–º –¥–µ—Ä–µ–≤—å–µ–≤
    xgb_model.train(X_train, y_train, X_val=X_val, y_val=y_val, num_rounds=n_estimators)
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    logger.info("–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
    metrics = xgb_model.evaluate(X_test, y_test)
    logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {metrics}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–æ—Å—Ç—É–ø–Ω—ã)
    if xgb_model.model is not None and xgb_model.feature_names is not None:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ XGBoost
            importance_dict = {name: score for name, score in 
                             zip(xgb_model.feature_names, xgb_model.model.get_score(importance_type='weight').values())}
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            logger.info(f"–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {sorted_importance[:10]}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {str(e)}")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º os –µ—â–µ —Ä–∞–∑ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –æ–±–ª–∞—Å—Ç–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏
    import os
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    today = datetime.now().strftime('%Y%m%d')
    model_path = xgb_model.save_model(f"xgb_{target_type}_{today}.json")
    logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    predictor = GoldPredictor()
    predictor.config['xgb_model_path'] = os.path.basename(model_path)
    predictor.save_config()
    logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞: xgb_model_path = {os.path.basename(model_path)}")
    
    return model_path

if __name__ == "__main__":
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    import argparse
    parser = argparse.ArgumentParser(description="–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ XGBoost –º–æ–¥–µ–ª–∏ –Ω–∞ 61 –ø—Ä–∏–∑–Ω–∞–∫–µ")
    parser.add_argument('--period', type=str, default='10y', help='–ü–µ—Ä–∏–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--use_bybit', action='store_true', default=True, help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Bybit –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--target_type', type=str, default='binary', 
                       choices=['binary', 'regression', 'classification'], help='–¢–∏–ø —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π')
    parser.add_argument('--horizon', type=int, default=1, help='–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ –¥–Ω—è—Ö)')
    parser.add_argument('--n_estimators', type=int, default=200, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤')
    parser.add_argument('--max_depth', type=int, default=5, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤')
    parser.add_argument('--learning_rate', type=float, default=0.1, help='–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
    
    args = parser.parse_args()
    
    # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model_path = retrain_xgboost(
        period=args.period,
        target_type=args.target_type,
        horizon=args.horizon,
        use_bybit=args.use_bybit,
        n_estimators=args.n_estimators,
        max_depth=args.max_depth,
        learning_rate=args.learning_rate
    )
    
    if model_path:
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ XGBoost –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (61 –ø—Ä–∏–∑–Ω–∞–∫)")
        print(f"üìÑ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")
        print(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: logs/retrain_xgboost.log")
